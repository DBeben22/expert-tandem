{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prototype Version 4\n",
    "This code will read data from an tsv file, this file contains associations of the name of a tandem spectra and their corresponding amino acids sequence. I will find the corresponding spectra in an mzML file and create a Dataframe from matches.\n",
    "<br>\n",
    "This code will then find the shortest spectra <b>visualize</b> it and <b>identify</b> the presumably correct peaks based on the match.\n",
    "This programs purpose is to recreate this spectra annotation as faithfully as possible just based on the distances between the peaks (which are assumed to be y-ions). The code will <b>recognize</b> amino acids that could fit in between these peaks.\n",
    "<br>\n",
    "This code will create a distance matrix and score every single distance between peaks and which of them could fit an amino acids or pair of amino acids between them. Using this distance matrix the code will find every single possible peptide. These are then given a confidence score referring to their likelyhood of being the true peptide. This confidence score is adapted from the 2003 paper by David Tabb named DirecTag https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2810657/\n",
    "<br>\n",
    "This approach of identifying peptides is called <b>DeNovo </b> and this code is based on a presentation by Nick Webb (https://www.weddslist.com/ms/tandem.html)\n",
    "\n",
    "I will investigate how well my programs predict the amino acid sequence by comparing the actual vs predicted sequence AND how well my confidence score works.\n",
    "\n",
    "At the end, in order to check my results, I will use the pyteomics.pylab_aux module to test my annotations and visualize the"
   ],
   "id": "7e2dbe66c55b42ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# basic dependencies and useful math/organization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "# to read mzML files\n",
    "from pyteomics import mzml\n",
    "\n",
    "# to visualize mzML\n",
    "from pyteomics import pylab_aux as pa, usi\n",
    "\n",
    "# to find peaks\n",
    "from scipy.signal import find_peaks\n",
    "from peakutils import indexes"
   ],
   "id": "initial_id",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## reading the files",
   "id": "c6a403cb98ded776"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# file that contains the associations between tandem spectra name and amino acids sequence\n",
    "df = pd.read_csv(\"../data/psm_a.tsv\", sep=\"\\t\")"
   ],
   "id": "9dd433a345b4683e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# file that contains the amino acids and their weights\n",
    "# TODO for now there is a distinction between \"I\" and \"L\"\n",
    "# They are indistinguishable by weight so I cant really know which one it is\n",
    "aa = pd.read_csv(\"../data/single_double_amino_acids.csv\")"
   ],
   "id": "cbf65ffffe0bca57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# this creates a dictionary of matches between the mzMl file and the psm_a.tsv\n",
    "# this should only return MS/MS where we have the Peptide sequence already identified.\n",
    "i = 0\n",
    "matches = []\n",
    "plotting_dict = None\n",
    "with mzml.MzML(mz_path) as reader:\n",
    "    for spectrum in reader:\n",
    "        # looking for the first match between the 2 files\n",
    "        for name in df[\"Spectrum\"]:\n",
    "            if name in spectrum.get('spectrum title') :\n",
    "                # print(spectrum[\"index\"], spectrum.get(\"spectrum title\"))\n",
    "                # Extract relevant information\n",
    "                matches.append([spectrum,df[df[\"Spectrum\"] == name][\"Peptide\"].sum(),\n",
    "                               df[df[\"Spectrum\"] == name][\"Hyperscore\"].sum()])\n",
    "                \"\"\"\n",
    "                spectrum_name = name\n",
    "                mz_array = spectrum['m/z array']\n",
    "                intensity_array = spectrum['intensity array']\n",
    "                precursor_mz = (spectrum['precursorList']['precursor']\n",
    "                                [0]['selectedIonList']['selectedIon'][0]['selected ion m/z'])\n",
    "\n",
    "                plotting_dict = {'m/z array': mz_array, 'intensity array': intensity_array}\n",
    "                \"\"\"\n",
    "        #         break\n",
    "        # if plotting_dict != None:\n",
    "        #     break\n",
    "m_df = (pd.DataFrame(matches, columns=[\"Spectrum\",\"Peptide\",\"Hyperscore\"])\n",
    "    .sort_values(by = [\"Hyperscore\"], axis=0, ascending= False)\n",
    "    .reset_index(drop=True))\n"
   ],
   "id": "948b68bfaede9f9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32f218a6ab4bc66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## deciding on which Peptide sequence to use\n",
    "I am going to aim for the shortest one for simplicity"
   ],
   "id": "b202dc6c38955740"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(min(m_df[\"Peptide\"], key = len))\n",
    "print(m_df[m_df[\"Peptide\"] == str(min(m_df[\"Peptide\"], key = len))])\n",
    "pep_loc = 7103"
   ],
   "id": "2069bdc98fda1e79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# collecting the data in variables\n",
    "peptide = m_df[\"Peptide\"].iloc[pep_loc]\n",
    "print(\"Peptide sequence:\", peptide)\n",
    "mz_array = m_df[\"Spectrum\"].iloc[pep_loc]['m/z array']\n",
    "intensity_array = m_df[\"Spectrum\"].iloc[pep_loc]['intensity array']\n",
    "precursor_mz = m_df[\"Spectrum\"].iloc[pep_loc]['precursorList']['precursor'][0]['selectedIonList']['selectedIon'][0]['selected ion m/z']\n",
    "plotting_dict = {'m/z array': mz_array, 'intensity array': intensity_array}\n"
   ],
   "id": "2fa14014b7b3d5ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7496dfcfd8f26da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Finding Peaks\n",
    "using sci_peak"
   ],
   "id": "fd3e95019a05a7b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "s1 = pd.DataFrame(plotting_dict)\n",
    "pa.plot_spectrum(plotting_dict)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.show()"
   ],
   "id": "cd82d9f707bd764e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sp_height = intensity_array.max()*0.05\n",
    "sp_dist = None\n",
    "sp_prom = None\n",
    "#TODO find ways to optimize for these parameters, possible based on characteristics of each spectrum\n",
    "# 5% of max height should be the cutoff threshold\n",
    "# i.e.: based on how long we expect the amino acid sequence to be\n",
    "# what determines wheter a peak is useful, is there someway we can find out?\n",
    "#\n",
    "\n",
    "sci_peak, _ = find_peaks(s1[\"intensity array\"],\n",
    "                      height=sp_height,\n",
    "                      distance=sp_dist,\n",
    "                      prominence=sp_prom\n",
    "                      )\n",
    "sns.set_theme(rc={'figure.figsize':(20,6)})\n",
    "sns.scatterplot(data = s1.iloc[sci_peak].reset_index(),\n",
    "                x = \"m/z array\",\n",
    "                y = \"intensity array\",\n",
    "                color = \"red\", alpha = 0.5).set_xticks(np.arange(0,1200,50))\n",
    "pa.plot_spectrum(plotting_dict)\n",
    "#plt.plot(np.zeros_like(x), \"--\", color=\"gray\")\n",
    "#plt.figure(figsize=(12,6))\n",
    "plt.show()"
   ],
   "id": "6f58c40384caae4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2bc8caa33731fa7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## automatically annotating the spectra with pyteomics\n",
    "based on the \"real\" peptide"
   ],
   "id": "1838c3e546ffe505"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pa.annotate_spectrum(plotting_dict, peptide, precursor_charge=2, backend='spectrum_utils',\n",
    "    ion_types='aby', title=peptide)\n",
    "#plt.figure(figsize=(12,6))\n",
    "plt.show()\n",
    "len(peptide)"
   ],
   "id": "4a87862a50350814"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function for finding the closes amino acids",
   "id": "aeaabbead8e7eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# cheesing an issue with the apply function\n",
    "# TODO pass this as an argument for the function instead of letting it access an outside variable\n",
    "combo_df = aa"
   ],
   "id": "386d6f28158ad4ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import math\n",
    "def find_closest_aa(value, thres = 2.5):\n",
    "    \"\"\" Find the closest amino acid to a given mass.\n",
    "    this code takes a dataframe with single amino acids and combinations of amino acids in this format\n",
    "\n",
    "        full    letter  short   comp    mono    mass    G           A           S           P   V etc.\n",
    "    0   glycine G       gly     c2h3no  57      57      g+g mass    g+a mass    g+s mass\n",
    "    1   alanine A       ala     c3h5no  71      71      a+g mass    a+a mass    a+s mass\n",
    "    etc.\n",
    "\n",
    "    using this dataframe and a given mass, it will find the closest amino acid\n",
    "     or combination of 2 amino acids to the given mass.\n",
    "    It will only return amino acids that are within the threshold.\n",
    "    It returns a list of lists, where each list contains the letter of the amino acid, its mass and the error.\n",
    "    \"\"\"\n",
    "    # TODO remove useless calculations from this like closeness_list having values that I never use\n",
    "    if math.isnan(value) == True:\n",
    "        return None\n",
    "    single_df = combo_df.iloc[:,:-22]\n",
    "    double_df = combo_df.set_index([\"letter\"]).iloc[\n",
    "                :,[i for i in range(-22, -0)]]\n",
    "    closeness_list = []\n",
    "    # find the closest single amino acids\n",
    "    loop_for_single = True\n",
    "    while loop_for_single:\n",
    "        aam_array = np.asarray(single_df[\"mono mass\"])\n",
    "        idx = (np.abs(aam_array - value)).argmin()\n",
    "        error = np.abs(aam_array[idx] - value)\n",
    "        if error > thres:\n",
    "            loop_for_single = False\n",
    "        else:\n",
    "            name_idx = single_df[\"letter\"].iloc[idx]\n",
    "            closeness_list.append([name_idx, aam_array[idx], error])\n",
    "            single_df = single_df.drop(single_df.index[idx])\n",
    "    # find closest combination of amino acids\n",
    "    loop_for_combo = True\n",
    "    while loop_for_combo:\n",
    "        error = (np.abs(double_df - value)).min().min()\n",
    "        r, c = np.where(double_df == error + value)\n",
    "        # if error wouldve been negative np.where will not find r, c\n",
    "        # and pass empty arrays creating error\n",
    "        if r.size == 0 :\n",
    "            # print(\"boink\")\n",
    "            r, c = np.where(double_df == value - error)\n",
    "        if error > thres:\n",
    "            loop_for_combo = False\n",
    "        else:\n",
    "            name_idx = double_df.index[r[0]]+ \"+\" + double_df.columns[c[0]]\n",
    "            closeness_list.append([name_idx, double_df.iloc[r[0],c[0]], error])\n",
    "            double_df.iloc[r[0],c[0]] = None\n",
    "    # print(\"closest aa is: \", name_idx, \" ,with mass: \",\n",
    "    # aam_array[idx], \"Da. With an error of: \", error, \"Da.\")\n",
    "    closeness_list.sort(key=lambda x: x[2])\n",
    "    if closeness_list:\n",
    "        # return closeness_list[0]\n",
    "        return closeness_list[0][0]\n",
    "    return None\n",
    "\n",
    "\n",
    "'''\n",
    "I would love to decided a closeness factor by iterating over the weights\n",
    "and seeing how close they are to each other on average. Does this make sense?\n",
    "'''"
   ],
   "id": "69133411b4dc542"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "39401a712f89dd8e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creating the distance Matrix",
   "id": "406875a1fb28b6ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mz_peaks = mz_array[sci_peak]\n",
    "intensity_peaks = intensity_array[sci_peak]\n",
    "mz_round = np.round(mz_peaks, decimals= 6)"
   ],
   "id": "32135de16340decb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# on my stackoverflow someone suggested a better way to create my distance matrix\n",
    "# however I am now so deep in this going back would cost too much time\n",
    "\n",
    "# this code builds a distance matrix for the given mz_array\n",
    "# unless there is already a file in the directory it can just read\n",
    "\n",
    "def rename(column):\n",
    "    new = mz_round[int(column)]\n",
    "    return new\n",
    "\n",
    "try:\n",
    "    df_aa = pd.read_csv(\"below_shortest_example_matrix_named.csv\").set_index(\"Unnamed: 0\")\n",
    "except:\n",
    "    distance_matrix = []\n",
    "    for column, i in zip(mz_round, range(len(mz_round))):\n",
    "        distance_matrix.append([])\n",
    "        for row in mz_round:\n",
    "            distance_matrix[i].append(np.abs(row - column))\n",
    "\n",
    "    df_dm = pd.DataFrame(distance_matrix)\n",
    "    df_dm.columns = df_dm.columns.map(str)\n",
    "\n",
    "    # for i in range(len(mz_round)):\n",
    "    #     for j in range(i):\n",
    "    #         df_dm.iat[i,j] = None\n",
    "    for i in range(len(mz_round)):\n",
    "        for j in range(len(mz_round)):\n",
    "            if j >= i:\n",
    "                df_dm.iat[i,j] = None\n",
    "            if df_dm.iat[i,j] < 55 or df_dm.iat[i,j] > 480:\n",
    "                df_dm.iat[i,j] = None\n",
    "\n",
    "    # if j <= i:\n",
    "    #     df_dm.iat[i,j] = None\n",
    "    # drop columns with no values (all NaN)\n",
    "    df_dm.dropna(axis = 1, how=\"all\", inplace = True)\n",
    "\n",
    "    print(\"starting mapping\")\n",
    "    df_aa = df_dm.map(find_closest_aa)\n",
    "    print(\"mapping complete\")\n",
    "\n",
    "    df_aa.rename(columns=rename, inplace=True)\n",
    "    df_aa.rename(index=rename, inplace=True)\n",
    "\n",
    "    df_aa.to_csv(\"below_shortest_example_matrix_named.csv\")\n",
    "\n",
    "    #have to reread so dictionaries are reconverted into strings\n",
    "    # this is stupid but makes the code work consistently with read csv files\n",
    "    df_aa = pd.read_csv(\"below_shortest_example_matrix_named.csv\").set_index(\"Unnamed: 0\")\n"
   ],
   "id": "e7247727f7147038"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6f0f552cdad46830"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## function to find all possible paths through this distance matrix",
   "id": "7cb59f8462f140da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO give this function somehow sensible arguments to pass\n",
    "# kids look away this function is not greatly formatted\n",
    "def find_all_paths(n = 1000):\n",
    "    # This is written to work form the highest peak down to the lowest similar to how its done by nick wedd.\n",
    "    # however my distance matrix removed all points below the diagonal meaning anytime I identify a hit of an amino acid it looks like follows\n",
    "    # hit a row: x and column: y. where y > x and since my program iterates over rows and then columns it sets the column to be the new row.\n",
    "    # which means it starts back at the top and repeats itself in a pattern. Ill have to change the orientation of the matrix.\n",
    "    full_pep_list = []\n",
    "\n",
    "    blacklist = []\n",
    "\n",
    "    for j in range(n):\n",
    "        path_one = []\n",
    "        peaks_one = []\n",
    "        cur_peak = float(mz_round[-1])\n",
    "        #\n",
    "        while cur_peak > float(mz_round[0]):\n",
    "            found = False\n",
    "            for column in reversed(df_aa.columns):\n",
    "                # print(\"conk\", type(aa))\n",
    "                peak_pos = np.where(mz_round == cur_peak)[0][0]\n",
    "                aa_inf = df_aa[column].iloc[peak_pos]#.values[0]\n",
    "                aa_int = intensity_peaks[peak_pos]\n",
    "                # print(\"row:\",mz_round[peak_pos],\"column: \", column,\"aa:\",aa_inf,\"int:\",aa_int)\n",
    "                #time.sleep(0.1)\n",
    "                # choosing the first possible connection always as of now\n",
    "                if isinstance(aa_inf, str) and peaks_one + [mz_round[peak_pos], float(column)] not in blacklist:\n",
    "                    # and peaks_one not in blacklist:# or float(column) not in Xblacklist):\n",
    "                    # print(\"\\n boingoloingo \\n\",mz_round[peak_pos],\"\\n\",column,\" \\n\")\n",
    "                    found = True\n",
    "                    # if peaks_one + [mz_round[peak_pos], float(column)] in blacklist:\n",
    "                    #     found = False\n",
    "                    #     print(\"WE HAVE BEEN DOWN THIS PATH BEFORE, ABORT MISSION AJDKSDFSDKFJ\")\n",
    "                    #     break\n",
    "                    path_one.append(aa_inf)\n",
    "                    peaks_one.append(mz_round[peak_pos])\n",
    "                    #peaks_one.append(mz_round[peak_pos])\n",
    "                    # ast.literal_eval is a security risk but I dont know a better way\n",
    "                    # Problem is that dictionaries get saved as string when .to_csv is applied\n",
    "                    cur_peak = float(column)\n",
    "                    last_peak = float(column)\n",
    "            if not found:\n",
    "                # print(\"skip to next row\")\n",
    "                cur_peak = float(mz_round[peak_pos-1])\n",
    "                found = False\n",
    "\n",
    "        peaks_one.append(last_peak)\n",
    "        blacklist.append(peaks_one)\n",
    "        # info_dic = {}\n",
    "        # for i in range(len(peaks_one)):\n",
    "        #     info_dic[i] = peaks_one[i]\n",
    "        full_pep_list.append([path_one, peaks_one])\n",
    "        #print(\"new peptide finished\")\n",
    "        #print(path_one)\n",
    "\n",
    "    return full_pep_list"
   ],
   "id": "1a77fca48dbb6460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "find_all_paths()",
   "id": "2238380711f1ff25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pd.DataFrame(full_pep_list)",
   "id": "a83627643a56c56b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO find a way to compute every single possible peptide\n",
    "# this will create soooo many peptides tho\n",
    "# TODO implement the DirecTag ranking methods.\n",
    "# TODO is there a heuristic for this???\n",
    "# like can I find a way to know ahead of time which path makes the most sense"
   ],
   "id": "af47c2417e5fb185"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## implement confidence scoring function",
   "id": "c0cd4a24877e2064"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## apply confidence score",
   "id": "96d944e7a110849d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## distribution of confidence scores",
   "id": "361c768febbbb42a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## visualize most confident peptide and its MS/MS",
   "id": "a280e11edd87725"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
